{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FgZfHCcAcQZx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "#from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "#from tensorflow.keras.preprocessing.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(SIZE,SIZE,1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='elu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to numpy arrays\n",
    "x_train = np.array(x_train, dtype=np.int8)\n",
    "y_train = np.array(y_train, dtype=np.int8)\n",
    "x_test = np.array(x_test, dtype=np.int8)\n",
    "y_test = np.array(y_test, dtype=np.int8)\n",
    "#Reshape the data into the shape accepted by the NN\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "# to categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(directory)):\n",
    "dirstr = 'matrixs/'\n",
    "directory = os.fsencode(dirstr)\n",
    "\n",
    "for index, file in enumerate(os.listdir(directory)):\n",
    "dirstr = 'shapes/circle/'\n",
    "directory = os.fsencode(dirstr)\n",
    "\n",
    "circles = []\n",
    "for index, file in enumerate(os.listdir(directory)):\n",
    "    circles.append(np.asarray(Image.open(dirstr + file.decode('ascii'))))\n",
    "training_data_len = math.ceil( len(dataset) *.9)\n",
    "training_data_len = math.ceil( len(dataset) *.8)\n",
    "#Convert to numpy arrays\n",
    "x_train = np.array(x_train, dtype=np.int8)\n",
    "y_train = np.array(y_train, dtype=np.int8)\n",
    "x_test = np.array(x_test, dtype=np.int8)\n",
    "y_test = np.array(y_test, dtype=np.int8)\n",
    "#Reshape the data into the shape accepted by the NN\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "# to categorical\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)\n",
    "history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "Y = []\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirstr = 'shapes/circle/'\n",
    "directory = fsencode(dirstr)\n",
    "\n",
    "circles = []\n",
    "\n",
    "for index, file in enumerate(os.listdir(directory)):\n",
    "    circle = np.asarray(Image.open(dirstr + file.decode('ascii')))\n",
    "    #Y.append(0)\n",
    "    data.append([cirkle, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirstr = 'shapes/sqare/'\n",
    "directory = os.fsencode(dirstr)\n",
    "\n",
    "squares = []\n",
    "for index, file in enumerate(os.listdir(directory)):\n",
    "    square = np.asarray(Image.open(dirstr + file.decode('ascii')))\n",
    "    #Y.append(1)\n",
    "    data.append([sqare, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirstr = 'shapes/star/'\n",
    "directory = fsencode(dirstr)\n",
    "\n",
    "star = []\n",
    "\n",
    "for index, file in enumerate(os.listdir(directory)):\n",
    "    star = np.asarray(Image.open(dirstr + file.decode('ascii')))\n",
    "    #Y.append(0)\n",
    "    data.append([star, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirstr = 'shapes/triangle/'\n",
    "directory = fsencode(dirstr)\n",
    "\n",
    "triangle = []\n",
    "\n",
    "for index, file in enumerate(os.listdir(directory)):\n",
    "    triangle = np.asarray(Image.open(dirstr + file.decode('ascii')))\n",
    "    #Y.append(0)\n",
    "    data.append([triangle, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q3g7q1kzjYpp"
   },
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset shapes not found. Available datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19sum\n\t- crema_d\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- div2k\n\t- dmlab\n\t- downsampled_imagenet\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gpt3\n\t- groove\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- i_naturalist2017\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- kitti\n\t- kmnist\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- malaria\n\t- math_dataset\n\t- mctaco\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quickdraw_bitmap\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- resisc45\n\t- robonet\n\t- rock_paper_scissors\n\t- rock_you\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- scicite\n\t- scientific_papers\n\t- sentiment140\n\t- shapes3d\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- vgg_face2\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wiki_bio\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- xnli\n\t- xquad\n\t- xsum\n\t- yelp_polarity_reviews\n\t- yes_no\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-00f0aef0b177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shapes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train[:100%]'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow_datasets\\core\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcs_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcs_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datasets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m   \u001b[0mdbuilder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mbuilder_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow_datasets\\core\\load.py\u001b[0m in \u001b[0;36mbuilder\u001b[1;34m(name, data_dir, **builder_init_kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m   \u001b[1;31m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mnot_found_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow_datasets\\core\\load.py\u001b[0m in \u001b[0;36mbuilder\u001b[1;34m(name, data_dir, **builder_init_kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;31m# Try loading the code (if it exists)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuilder_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_abstract\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow_datasets\\core\\load.py\u001b[0m in \u001b[0;36mbuilder_cls\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_abstract\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mregistered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_DATASET_REGISTRY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mregistered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_DATASET_REGISTRY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# pytype: disable=bad-return-type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m: Dataset shapes not found. Available datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19sum\n\t- crema_d\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- div2k\n\t- dmlab\n\t- downsampled_imagenet\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gpt3\n\t- groove\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- i_naturalist2017\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- kitti\n\t- kmnist\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- malaria\n\t- math_dataset\n\t- mctaco\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quickdraw_bitmap\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- resisc45\n\t- robonet\n\t- rock_paper_scissors\n\t- rock_you\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- scicite\n\t- scientific_papers\n\t- sentiment140\n\t- shapes3d\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- vgg_face2\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wiki_bio\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- xnli\n\t- xquad\n\t- xsum\n\t- yelp_polarity_reviews\n\t- yes_no\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n"
     ]
    }
   ],
   "source": [
    " tfds.load('shapes', split=['train[:100%]'], with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaciATb2qCuS"
   },
   "outputs": [],
   "source": [
    "\n",
    "def resize_image(img, label):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.image.resize(img, (SIZE, SIZE))\n",
    "    img = img / 112.5\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5NDzrrErxNM"
   },
   "outputs": [],
   "source": [
    "train_resized = train[0].map(resize_image)\n",
    "train_batches = train_resized.shuffle(1000).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ACc5ZC4sr7c"
   },
   "outputs": [],
   "source": [
    "base_layers = tf.keras.applications.MobileNetV2(input_shape=(SIZE, SIZE, 3)),  include_top=False)\n",
    "base_layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmrcF12TuDe3"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                            base_layers,\n",
    "                            GlobalAveragePooling2D(),\n",
    "                            Dropout(0.2),\n",
    "                            Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbdylAt7uKw_"
   },
   "outputs": [],
   "source": [
    "model.fit(train_batches, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jWKoLX2uNmY"
   },
   "outputs": [],
   "source": [
    "#for i in range(62):\n",
    "    #img = load_img(f'C:/Новая папка/{i+1}.jpg')\n",
    "    #img_array = img_to_array(img)\n",
    "    #img_resized, _ = resize_image(img_array, _)\n",
    "    #img_expended = np.expended_dims(img_resized, axis=0)\n",
    "    #prediction = model.predict(img_expended)[0][0]\n",
    "    pred_label = 'КОТ' if prediction < 0.5 else 'СОБАКА'\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'{pred_label} {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJ9JIbENd9pzYkA5XstAbZ",
   "collapsed_sections": [],
   "name": "Cats_VS_Dogs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
